{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Advanced Forecasting Pipelines\n",
    "\n",
    "In the previous notebook, we considered\n",
    "* sequential pipelines\n",
    "* tuning their hyperparameters\n",
    "\n",
    "This notebook is about:\n",
    "* tuning the structure of sequential pipelines\n",
    "* introducing graphical pipelines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_arrow_head, load_longley, load_macroeconomic\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import (\n",
    "    ColumnEnsembleForecaster,\n",
    "    ForecastX,\n",
    "    MultiplexForecaster,\n",
    "    make_reduction,\n",
    ")\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ForecastingGridSearchCV,\n",
    "    SlidingWindowSplitter,\n",
    "    temporal_train_test_split,\n",
    ")\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.sarimax import SARIMAX\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_error\n",
    "from sktime.pipeline.pipeline import Pipeline\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.exponent import ExponentTransformer\n",
    "from sktime.transformations.series.subset import ColumnSelect\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Tuning the Pipeline's Structure (AutoML)\n",
    "In the previous notebook, we performed a grid search to find the best hyperparameters. However, also the structure of the pipeline is a hyperparamter. Thus, for tuning this hyperparameter, `sktime` contains\n",
    "* MultiplexForecasters\n",
    "* OptionalPassthrough\n",
    "* ...\n",
    "\n",
    "That are explained in the following before showing an AutoML example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Tuning ComponentsModel selection\n",
    "\n",
    "Pipeline structure choices influence performance\n",
    "\n",
    "`sktime` allows to expose these choices via structural compositors:\n",
    "\n",
    "* switch between transform/forecast: `MultiplexTransformer`, `MultiplexForecaster`\n",
    "* transformer on/off: `OptionalPassthrough`\n",
    "* sequence of transformers: `Permute`\n",
    "\n",
    "Combine with pipelines and `FeatureUnion` for rich structure space\n",
    "\n",
    "#### `MultiplexForecaster`\n",
    "We can use the `MultiplexForecaster` to compare the performance of different forecasters. This approach might be useful if we want to compare the performance of different forecasters that have been tuned and fitted already separately. The `MultiplexForecaster` is just a forecaster compostition that provides a parameters `selected_forecaster: List[str]` that can be tuned with a grid search. The other parameters of the forecasters are not tuned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'selected_forecaster': 'theta'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.forecasting.compose import MultiplexForecaster\n",
    "\n",
    "forecaster = MultiplexForecaster(\n",
    "    forecasters=[\n",
    "        (\"naive\", NaiveForecaster()),\n",
    "        (\"stl\", STLForecaster()),\n",
    "        (\"theta\", ThetaForecaster()),\n",
    "    ]\n",
    ")\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster=forecaster,\n",
    "    param_grid={\"selected_forecaster\": [\"naive\", \"stl\", \"theta\"]},\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "gscv.fit(y)\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Optional Passthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sktime` there is a transformer composition called `OptionalPassthrough()` which gets a transformer as an argument and a param `passthrough: bool`. Setting `passthrough=True` will return an identity transformation for the given data. Setting `passthrough=False` will apply the given inner transformer on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Period\n1991-01    266.0\n1991-02    145.9\n1991-03    183.1\n1991-04    119.3\n1991-05    180.3\nFreq: M, Name: Number of shampoo sales, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.transformations.series.compose import OptionalPassthrough\n",
    "\n",
    "transformer = OptionalPassthrough(transformer=Detrender(), passthrough=True)\n",
    "transformer.fit_transform(y_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Period\n1991-01    266.0\n1991-02    145.9\n1991-03    183.1\n1991-04    119.3\n1991-05    180.3\nFreq: M, Name: Number of shampoo sales, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Period\n1991-01    130.376344\n1991-02      1.503263\n1991-03     29.930182\n1991-04    -42.642900\n1991-05      9.584019\nFreq: M, Name: Number of shampoo sales, dtype: float64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = OptionalPassthrough(transformer=Detrender(), passthrough=False)\n",
    "transformer.fit_transform(y_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation of transformers\n",
    "\n",
    "Given a set of four different transformers, we would like to know which permutation (ordering) of the four transformers is having the best error. In total there are `4! = 24` different permutations. We can use the `GridSearchCV` to find the best permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1459108173.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[6], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    Please see appendix section for an example with exogenous data\u001B[0m\n\u001B[1;37m           ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.compose import Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = TransformedTargetForecaster(\n",
    "    steps=[\n",
    "        (\"detrender\", Detrender()),\n",
    "        (\"deseasonalizer\", Deseasonalizer()),\n",
    "        (\"power\", TabularToSeriesAdaptor(PowerTransformer())),\n",
    "        (\"scaler\", TabularToSeriesAdaptor(RobustScaler())),\n",
    "        (\"forecaster\", ExponentialSmoothing()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"permutation\": [\n",
    "        [\"detrender\", \"deseasonalizer\", \"power\", \"scaler\", \"forecaster\"],\n",
    "        [\"power\", \"scaler\", \"detrender\", \"deseasonalizer\", \"forecaster\"],\n",
    "        [\"scaler\", \"deseasonalizer\", \"power\", \"detrender\", \"forecaster\"],\n",
    "        [\"deseasonalizer\", \"power\", \"scaler\", \"detrender\", \"forecaster\"],\n",
    "    ]\n",
    "}\n",
    "permuted = Permute(estimator=forecaster, permutation=None)\n",
    "\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster=permuted,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring=MeanSquaredError(square_root=True),\n",
    ")\n",
    "\n",
    "permuted = gscv.fit(y, fh=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worst params\n",
    "gscv.cv_results_.sort_values(by=\"mean_test_MeanSquaredError\", ascending=True).iloc[-1][\n",
    "    \"params\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 AutoML and Forecasting\n",
    "\n",
    "Taking all incredients from above examples, we can build a forecaster that comes close to what is usually called [AutoML](https://en.wikipedia.org/wiki/Automated_machine_learning).\n",
    "With AutoML we aim to automate as many steps of an ML model creation as possible. The main compositions from `sktime` that we can use for this are:\n",
    "- `TransformedTargetForecaster`\n",
    "- `ForecastingPipeline`\n",
    "- `ForecastingGridSearchCV`\n",
    "- `OptionalPassthrough`\n",
    "- `Permute` [Not Covered in this workshop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate example\n",
    "Please see appendix section for an example with exogenous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_y = TransformedTargetForecaster(\n",
    "    steps=[\n",
    "        (\"detrender\", OptionalPassthrough(Detrender())),\n",
    "        (\"deseasonalizer\", OptionalPassthrough(Deseasonalizer())),\n",
    "        (\"scaler\", OptionalPassthrough(TabularToSeriesAdaptor(RobustScaler()))),\n",
    "        (\"forecaster\", STLForecaster()),\n",
    "    ]\n",
    ")\n",
    "permuted_y = Permute(estimator=pipe_y, permutation=None)\n",
    "\n",
    "param_grid = {\n",
    "    \"permutation\": [\n",
    "        [\"detrender\", \"deseasonalizer\", \"scaler\", \"forecaster\"],\n",
    "        [\"scaler\", \"deseasonalizer\", \"detrender\", \"forecaster\"],\n",
    "    ],\n",
    "    \"estimator__detrender__passthrough\": [True, False],\n",
    "    \"estimator__deseasonalizer__passthrough\": [True, False],\n",
    "    \"estimator__scaler__passthrough\": [True, False],\n",
    "    \"estimator__scaler__transformer__transformer__with_scaling\": [True, False],\n",
    "    \"estimator__scaler__transformer__transformer__with_centering\": [True, False],\n",
    "    \"estimator__forecaster__sp\": [4, 8, 12],\n",
    "}\n",
    "\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster=permuted_y,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring=MeanSquaredError(square_root=True),\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "\n",
    "gscv.fit(y=y_train, fh=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.cv_results_[\"mean_test_MeanSquaredError\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.cv_results_[\"mean_test_MeanSquaredError\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 Graphical Pipeline\n",
    "\n",
    "### What are Graphical Pipelines?\n",
    "Recap sequential pipelines:\n",
    "\n",
    "<img src=\"img/sequential_pipeline.png\" width=750 />\n",
    "\n",
    "Many tasks are non-sequential. To solve this two possibilities exist:\n",
    "1. Nesting Sequential Pipelines.\n",
    "2. Using Graphical Pipelines.\n",
    "\n",
    "\n",
    "Thus, there is the generalised graphial pipeline.\n",
    "* Graphical means that different steps may share the same predecessor or provide their outputs to the same successor (the dataflows can branch and merge).\n",
    "<img src=\"img/graphical_pipeline.png\" width=750 />\n",
    "\n",
    "\n",
    "* Generalised means that the pipeline can be used for multiple tasks (e.g. forecasting, classification, ...).\n",
    "\n",
    "**Note**\n",
    "\n",
    "The graphical pipeline is still experimental. Thus, this graphical should not used in production. However, we would be happy to get feedback on the graphical pipeline.\n",
    "\n",
    "\n",
    "\n",
    "### Potential Use-Cases\n",
    "There exist various potential use-case for the graphical pipeline. In the following, we focus on a forecasting and a classification pipeline.\n",
    "#### Forecasting Use-Case for Graphical Pipelines\n",
    "\n",
    "\n",
    "The input of forecasters depends on the output of other forecasters, which same the same input.\n",
    "* Forecaster could use the same preprocessing (branching of data flow)\n",
    "* Forecaster could use outputs of multiple predeccessors (merging of data flow)\n",
    "\n",
    "<img src=\"img/graphical_pipeline_example.png\" width=900 />\n",
    "\n",
    "\n",
    "#### Classification Use-Case for Graphical Pipelines\n",
    "\n",
    "\n",
    "The input of classifier are different features and not all of are observable. Idea: Use a soft sensor: I.e., a regressor for the non-observable features.\n",
    "\n",
    "<img src=\"img/graphical_pipeline_softsensor.png\" width=900 />\n",
    "\n",
    "**Note:** The current experimental state of the graphical pipeline does not fully support this use-case. However, we are working on this. If you are interested in this use-case and want to contribute, please contact us.\n",
    "\n",
    "### Credits\n",
    "The graphical pipeline was first developed by pyWATTS [1] and was then adapted for sktime. The original implementation can be found [pyWATTS](https://github.com/KIT-IAI/pyWATTS). pyWATTS is a open source library developed at the Institute of Applied Informatics and Automation at the KIT and funded by HelmholtzAI.\n",
    "\n",
    "> [1] Heidrich, Benedikt, et al. \"pyWATTS: Python workflow automation tool for time series.\" arXiv preprint arXiv:2106.10157 (2021).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2.1 Constructing simple Graphical Pipelines for Forecasting\n",
    "\n",
    "Two Ways to create graphical pipelines:\n",
    "\n",
    "1. Pass all steps to the pipeline during initialisation as for the sequential pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 Pipeline Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "differencer = Differencer()\n",
    "\n",
    "general_pipeline = Pipeline(\n",
    "    [\n",
    "        {\"skobject\": differencer, \"name\": \"differencer\", \"edges\": {\"X\": \"y\"}},\n",
    "        {\n",
    "            \"skobject\": SARIMAX(),\n",
    "            \"name\": \"sarimax\",\n",
    "            \"edges\": {\"X\": \"X\", \"y\": \"differencer\"},\n",
    "        },\n",
    "        {\n",
    "            \"skobject\": differencer,\n",
    "            \"name\": \"differencer_inv\",\n",
    "            \"edges\": {\"X\": \"sarimax\"},\n",
    "            \"method\": \"inverse_transform\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The pipeline can be visualised as follows:\n",
    "<img src=\"img/forecasting_pipeline.png\" width=750 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "general_pipeline = Pipeline()\n",
    "differencer = Differencer()\n",
    "\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    differencer, \"differencer\", edges={\"X\": \"y\"}\n",
    ")\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    SARIMAX(), \"sarimax\", edges={\"X\": \"X\", \"y\": \"differencer\"}\n",
    ")\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    differencer, \"differencer_inv\", edges={\"X\": \"sarimax\"}, method=\"inverse_transform\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Summary of the arguments:\n",
    "The `add_step`'s parameter or key of the dicts in the step list during initialisation are:\n",
    "\n",
    "* skobject: The sktime object added to the pipeline\n",
    "* name: The name of the step\n",
    "* edges: The keys of the dictionary indicate the input of the skobject (X or y), and the values are the names of the steps that should be connected to the input argument. Note subsetting using `__` and feature union via lists are supported.\n",
    "* method: The skobject's method that should be called. If not provided, the default method would be inferred based on the added skobject. This parameter is used for the inverse_transform method. Optional.\n",
    "* kwargs: Additional keyword arguments passed to the sktime object. Optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fitting and predicting works as for any sktime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = load_longley()\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X)\n",
    "\n",
    "general_pipeline.fit(y=y_train, X=X_train, fh=[1, 2, 3, 4])\n",
    "general_pipeline.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2.2 Constructing Graphical Pipelines for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Graphical Pipeline by initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Again, also using `add_step` is possible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "general_pipeline = Pipeline()\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    ExponentTransformer(), \"exponent\", edges={\"X\": \"X\"}\n",
    ")\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    KNeighborsTimeSeriesClassifier(), \"classifier\", edges={\"X\": \"exponent\", \"y\": \"y\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This pipeline can be visualised as follows:\n",
    "\n",
    "<img src=\"img/classification_pipeline.png\" width=750 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = load_arrow_head(split=\"train\", return_X_y=True)\n",
    "general_pipeline.fit(X=X, y=y)\n",
    "general_pipeline.predict(X=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2.3 Becoming more complex\n",
    "The considered use-case is to forecast the inflation using forecasts of the real gross domestic product, real disposable personal income, and the unemployment rate. Furthermore the unemployment rate is forecasted using the same features except the unemployment rate itself.\n",
    "\n",
    "<img src=\"img/graphical_pipeline_example.png\" width=750 />\n",
    "\n",
    "\n",
    "The data is taken from the macrodata dataset from the statsmodels package.\n",
    "\n",
    "**Note** We stick with the `add_step` in the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline()\n",
    "sklearn_scaler = StandardScaler()\n",
    "sktime_scaler = TabularToSeriesAdaptor(sklearn_scaler)\n",
    "deseasonalizer = Deseasonalizer(sp=4)\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    sktime_scaler, name=\"scaler\", edges={\"X\": \"X__realgdp_realdpi_unemp\"}\n",
    ")\n",
    "pipeline = pipeline.add_step(\n",
    "    deseasonalizer, name=\"deseasonalizer\", edges={\"X\": \"X__realgdp_realdpi\"}\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_gdp\",\n",
    "    edges={\"y\": \"deseasonalizer__realgdp\"},\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_dpi\",\n",
    "    edges={\"y\": \"deseasonalizer__realdpi\"},\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_unemp\",\n",
    "    edges={\n",
    "        \"y\": \"scaler__unemp\",\n",
    "        \"X\": [\n",
    "            \"forecaster_gdp\",\n",
    "            \"forecaster_dpi\",\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_inflation\",\n",
    "    edges={\"X\": [\"forecaster_dpi\", \"forecaster_unemp\"], \"y\": \"y\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_macroeconomic()\n",
    "\n",
    "X = data[[\"realgdp\", \"realdpi\", \"unemp\"]]\n",
    "y = data[[\"infl\"]]\n",
    "fh = ForecastingHorizon([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X=X, fh=fh)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline.fit(y=y_train, X=X_train, fh=fh)\n",
    "result = pipeline.predict(X=None, fh=y_test.index)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### But what are the best hyperparameters?\n",
    "\n",
    "* which forecaster should be used for which variable -> `MultiplexForecaster`\n",
    "* what should be the hyperparameters of the forecaster\n",
    "* which features should be used for the different forecasters -> Tune the edges of the graphical pipeline!\n",
    "\n",
    "<img src=\"img/graphical_pipeline_example_grid.png\" width=900 />\n",
    "\n",
    "**Idea:** Combine graphical pipeline with ForecastingGridSearchCV.\n",
    "\n",
    "1. Specify the parameter grid:\n",
    "\n",
    "The keys of the dictionary are the parameters' in the pipeline, and the values specify which options should be tested.\n",
    "Keys have the following structure: parameter of a step `<step_name>__skobject__<parameter-name>` and input edges of a step `<step-name>__edges_<Xory>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"forecaster_inflation__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "    \"forecaster_unemp__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "    \"forecaster_dpi__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "    \"forecaster_gdp__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "    \"forecaster_inflation__edges__X\": [\n",
    "        [\"forecaster_unemp\"],\n",
    "        [\"forecaster_unemp\", \"forecaster_dpi\"],\n",
    "    ],\n",
    "    \"forecaster_unemp__edges__X\": [\n",
    "        [],\n",
    "        [\"forecaster_dpi\"],\n",
    "        [\"forecaster_gdp\", \"forecaster_dpi\"],\n",
    "    ],\n",
    "    \"deseasonalizer__edges__X\": [\"X__realgdp_realdpi\", \"scaler__realgdp_realdpi\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Initialise the gridsearch using pipeline, cross-validation strategy, scoring, and param_grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridcv = ForecastingGridSearchCV(\n",
    "    pipeline,\n",
    "    cv=SlidingWindowSplitter(\n",
    "        window_length=len(X_train) - 20,\n",
    "        step_length=4,\n",
    "        fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    ),\n",
    "    scoring=mean_absolute_error,\n",
    "    param_grid=param_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Call fit on the gridsearch object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridcv.fit(y=y_train, X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridcv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = gridcv.predict(X=None, fh=y_test.index)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### How does the graphical pipeline compare to the sequential pipeline?\n",
    "\n",
    "Let us try to implement a simplified version of the above example using sequential pipelines with nesting.\n",
    "<img src=\"img/graphical_pipeline_simplified.png\" width=900 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create sequential pipelines for forecasting the GDP, DPI and unemployment rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forecasting_pipeline_gdp = (\n",
    "    ColumnSelect([\"realgdp\"])  # To train the forecaster only on the realgdp column\n",
    "    * Deseasonalizer()\n",
    "    * MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "forecasting_pipeline_dpi = (\n",
    "    ColumnSelect([\"realdpi\"])\n",
    "    * Deseasonalizer()\n",
    "    * MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "forecasting_pipeline_unemp = (\n",
    "    ColumnSelect([\"unemp\"])\n",
    "    * Deseasonalizer()\n",
    "    * MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Use ColunmEnsembleForecaster to combine the forecasts of the DPI, GDP, UNEMP. (Union of forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_inflation_forecast = ColumnEnsembleForecaster(\n",
    "    [\n",
    "        (\"realdpi\", forecasting_pipeline_dpi, \"realdpi\"),\n",
    "        (\"realgdp\", forecasting_pipeline_gdp, \"realgdp\"),\n",
    "        (\"unemp\", forecasting_pipeline_unemp, \"unemp\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create the inflation forecaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inflation_forecast = ForecastX(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    input_inflation_forecast,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inflation_forecast.fit(y=y_train, X=X_train, fh=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inflation_forecast.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ok, we can built it, but what about the hyperparameter tuning? Let us investigate the paramters.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inflation_forecast.get_params(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Uff..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "### Advantages of graphical pipelines\n",
    "* Enable an easy implementation of complex pipelines\n",
    "    * By nesting sequential pipelines, even a simplified version of the graphical pipeline is very complicat to implement.\n",
    "    * By nesting sequential pipelines, some graphical pipelines are not possible to implement (e.g., the example with coupled ForecastX).\n",
    "* Preprocessing steps can not be shared between the different forecasters.\n",
    "* The parameter structure can be very complex for the sequential pipelines.\n",
    "* In a complex scenario, how would you fine-tune the edges?\n",
    "\n",
    "### Advantages of sequential pipelines\n",
    "* Constructing simple pipelines is very easy.\n",
    "* Inverse operations are automatically applied.\n",
    "* This is a mature feature compared to the experimental graphical pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Credits: notebook 2 - pipelines\n",
    "\n",
    "notebook creation: benheid (graphical pipeline, overall), AutoML is based on pyData global 2022 notebook created by aiwalter.\n",
    "\n",
    "forecaster pipelines: fkiraly, aiwalter\\\n",
    "transformer pipelines & compositors: fkiraly, mloning, miraep8\\\n",
    "dunder interface: fkiraly, miraep8\\\n",
    "graphical pipeline: benheid, fkiraly\\\n",
    "\n",
    "tuning, autoML: mloning, fkiraly, aiwalter\\\n",
    "CV and splitters: mloning, kkoralturk, khrapovs\\\n",
    "forecasting metrics: mloning, aiwalter, rnkuhns, fkiraly\\\n",
    "backtesting, evaluation: aiwalter, mloning, fkiraly, topher-lo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pydata22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e61b44dca3bf47c8973c8cd627825697e2dad493e19dd6592afda0a0a3c312a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
