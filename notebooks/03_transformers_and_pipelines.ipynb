{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0 Introduction\n",
    "\n",
    "## 0.1 What is `sktime`?\n",
    "* sktime is a python library for time-series learning tasks!\n",
    "* If you are interested in a more in-depth introduction to sktime - check out a previous pydata tutorial of ours, and of course visit our website!\n",
    "* We love new contributors. Even if you are new to open source software developement! Check out our website with some tips on how to get started.\n",
    "* sktime is a scikit-learn (sklearn)-like library - a popular data science library! Why we like sklearn:\n",
    "    * unified interface\n",
    "    * modular design\n",
    "    * parts are composable\n",
    "    * simple specification language\n",
    "\n",
    "\n",
    "To scikit learn-like estimators you need to do 3 things:\n",
    "\n",
    "* Instantiate your model of choice\n",
    "* Fit the instance of your model\n",
    "* Use that fitted instance to predict new data!\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 What is forecasting?\n",
    "In forecasting, past data is used to make temporal forward predictions of a time series. This is notably different from tabular prediction tasks supported by scikit-learn and similar libraries.\n",
    "\n",
    "<img src=\"img/forecasting.png\" width=750 />\n",
    "\n",
    "\n",
    "sktime provides a common, scikit-learn-like interface to a variety of classical and ML-style forecasting algorithms, together with tools for building pipelines and composite machine learning models, including temporal tuning schemes, or reductions such as walk-forward application of scikit-learn regressors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.3 Agenda\n",
    "1. Transformers and Forecasting in `sktime`\n",
    "    *  Transformers\n",
    "    *  Forecasting\n",
    "2. Advanced Forecasting\n",
    "    *  AutoML\n",
    "    *  Graphical Pipelines\n",
    "3. Evaluation and Benchmarking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transformers in `sktime`\n",
    "* overview of transformer features\n",
    "\n",
    "    * types of transformers - input types, output types\n",
    "    * broadcasting/vectorization to panel, hierarchical, multivariate\n",
    "    * searching for transformers using `all_estimators`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Wherefore transformers?\n",
    "\n",
    "Tranformers in `sktime` referr to a catch-all term that encompses modular data processing steps.\n",
    "\n",
    "We use this term in the `sklearn` sense, so this is unrelated to transformers in NLP or deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose we want to forecast this well-known dataset\n",
    "(airline passengers by year in a fixed scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "y = load_airline()\n",
    "plot_series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observations:\n",
    "\n",
    "* there is seasonal periodicity, 12 month period\n",
    "* seasonal periodicity looks multiplicative (not additive) to trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea: forecast might be easier\n",
    "\n",
    "* with seasonality removed\n",
    "* on logarithmic value scale (multiplication becomes addition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Manual tranformations: doing things the wrong way\n",
    "\n",
    "Maybe doing this manually step by step is a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_log = np.log(y)\n",
    "\n",
    "fig, ax = plot_series(y_log, title=\"log(y)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this looks additive now!\n",
    "\n",
    "ok, what next - deaseasonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "seasonal_result = seasonal_decompose(y_log, period=12)\n",
    "seasonal = seasonal_result.seasonal\n",
    "y_log_deseasonalised = y_log - seasonal\n",
    "\n",
    "fig, ax = plot_series(y_log_deseasonalised, title=\"log(y) - seasonality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(seasonal, resid, labels=[\"seasonal component\", \"residual component\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now:\n",
    "\n",
    "* forecast on this\n",
    "* add back seasonal component\n",
    "* invert logarithm (exponentiate)\n",
    "\n",
    "start with forecast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import TrendForecaster\n",
    "\n",
    "forecaster = TrendForecaster()\n",
    "\n",
    "fh = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] # Alternatively: list(range(1, 13))\n",
    "y_pred = forecaster.fit_predict(y_log_deseasonalised, fh=fh)\n",
    "\n",
    "fig, ax = plot_series(\n",
    "    y_log_deseasonalised,\n",
    "    y_pred,\n",
    "    labels=[\"log(y) - seasonality\", \"y_pred\"],\n",
    "    title=\"Trend forecast over log(y) - seasonality\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks reasonable!\n",
    "\n",
    "Now to turn this into a forecast of the original y ...\n",
    "\n",
    "* add seasonal\n",
    "* invert the logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_add_seasonality = y_pred + seasonal[0:12].values\n",
    "y_pred_orig = np.exp(y_pred_add_seasonality)\n",
    "\n",
    "fig, ax = plot_series(y, y_pred_orig, labels=[\"y\", \"y_pred\"], title=\"Final forecast (manual approach)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, done! and it only took us 10 years.\n",
    "\n",
    "Maybe there is a better way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 `sktime` transformers: doing things the right way\n",
    "\n",
    "\n",
    "Solution: use transformers & pipelines!\n",
    "\n",
    "Same interface at every step! Easily composable!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import TrendForecaster\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "\n",
    "y = load_airline()\n",
    "\n",
    "forecaster = LogTransformer() * Deseasonalizer(sp=12) * TrendForecaster()\n",
    "\n",
    "fh = list(range(1, 13))\n",
    "y_pred = forecaster.fit_predict(y, fh=fh)\n",
    "\n",
    "fig, ax = plot_series(y, y_pred, labels=[\"y\", \"y_pred\"], title=\"Final forecast with sktime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what happened here?\n",
    "\n",
    "The \"chain\" operator `*` creates a \"forecasting pipeline\"\n",
    "\n",
    "Has the same interface as all other forecasters! No additional data fiddling!\n",
    "\n",
    "Transformers \"slot in\" as standardized components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this in more detail:\n",
    "\n",
    "* `sktime` transformers interface\n",
    "* `sktime` pipeline building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Transformers - More Detailed\n",
    "\n",
    "* transformer interface\n",
    "* transformer types\n",
    "* searching transformers by type\n",
    "* broadcasting/vectorization to panel & hierarchical data\n",
    "* transformers and pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 What are transformers? <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "Transformer = modular data processing steps commonly used in machine learning\n",
    "\n",
    "(\"transformer\" used in the sense of `scikit-learn`)\n",
    "\n",
    "Transformers are estimators that:\n",
    "\n",
    "* are fitted to a batch of data via `fit(data)`, changing its state\n",
    "* are applied to another batch of data via `transform(X)`, producing transformed data\n",
    "* may have an `inverse_transform(X)`\n",
    "\n",
    "In `sktime`, input `X` to `fit` and `transform` is typically a time series or a panel (collection of time series)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic use of an `sktime` time series transformer is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare the data\n",
    "from sktime.utils._testing.series import _make_series\n",
    "\n",
    "X = _make_series()\n",
    "X_train = X[:7]\n",
    "X_test = X[7:12]\n",
    "# X_train and X_test are both pandas.Series\n",
    "\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. construct the transformer\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "\n",
    "# trafo is an sktime estimator inheriting from BaseTransformer\n",
    "# Box-Cox transform with lambda parameter fitted via mle\n",
    "trafo = BoxCoxTransformer(method=\"mle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. fit the transformer to training data\n",
    "trafo.fit(X_train)\n",
    "\n",
    "# 4. apply the transformer to transform test data\n",
    "# Box-Cox transform with lambda fitted on X_train\n",
    "X_transformed = trafo.transform(X_test)\n",
    "\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training and test set is the same, step 3 and 4 can be carried out more concisely (and sometimes more efficiently) by using `fit_transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3+4. apply the transformer to fit and transform on the same data, X\n",
    "X_transformed = trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Different types of transformers <a class=\"anchor\" id=\"section_1_2\"></a>\n",
    "\n",
    "`sktime` distinguishes different types of transformer, depending on the input type of `fit` and `transform`, and the output type of `transform`.\n",
    "\n",
    "Common types of transformation in `sktime`:\n",
    "\n",
    "| from | to | base class | examples (sci) | examples (`sktime`) |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| time series | scalar features | `BaseTransformer` (`Primitives` output) | `tsfresh`, or 7-number-summary | `Catch22`,`SummaryTransformer` |\n",
    "| time series | time series | `BaseTransformer` (`Series`, `instancewise`)  | detrending, smoothing, filtering, lagging | `Detrender`,`Differencer`, `Lag`, `Filter` |\n",
    "| time series panel | also a panel | `BaseTransformer` (`Series` output)  | principal component projection | `PCATransformer`,`PaddingTransformer` |\n",
    "| two feature vectors | a scalar | `BasePairwiseTransformer` | Euclidean distance, L1 distance | `ScipyDist`, `AggrDist`, `FlatDist` |\n",
    "| two time series | a scalar | `BasePairwiseTransformerPanel` | DTW distance, alignment kernel | `DtwDist`, `EditDist` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the difference, we compare two transformers with different output:\n",
    "\n",
    "* the Box-Cox transformer `BoxCoxTrannsformer`, which transforms a time series to a time series\n",
    "* the summary transformer `SummaryTransformer`, which transforms a time series to scalars such as the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "y = load_airline()\n",
    "\n",
    "boxcox = BoxCoxTransformer()\n",
    "summary = SummaryTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoxCoxTransformer() produces a pd.Series\n",
    "boxcox.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SummaryTransformer() produces a (set of) scalar (values)\n",
    "summary.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For time series transformers, the metadata tags describe the expected output of `transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_trafo.get_tag(\"scitype:transform-output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_trafo.get_tag(\"scitype:transform-output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find transformers, use `all_estimators` and filter by tags:\n",
    "\n",
    "* `\"scitype:transform-output\"` - the output scitype. `Series` for time series, `Primitives` for primitive features (float, categories), `Panel` for collections of time series.\n",
    "* `\"scitype:transform-input\"` - the input scitype. `Series` for time series.\n",
    "* `\"scitype:instancewise\"` - If `True`, vectorized operation per series. If `False`, uses multiple time series non-trivially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: find all transformers that output time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "# now subset to transformers that extract scalar features\n",
    "all_estimators(\n",
    "    \"transformer\",\n",
    "    as_dataframe=True,\n",
    "    filter_tags={\"scitype:transform-output\": \"Series\"},\n",
    "    suppress_import_stdout=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complete overview on transformer types and tags is given in the `sktime` transformers tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Broadcasting aka vectorization of transformers <a class=\"anchor\" id=\"section_1_3\"></a>\n",
    "\n",
    "`sktime` transformers may be natively univariate, or apply only to a single time series.\n",
    "\n",
    "Even if this is the case, they broadcast across variables and instances of time series, where applicable (als known as vectorization in `numpy` parlance).\n",
    "\n",
    "This ensures that all `sktime` transformers can be applied to multivariate and multi-instance (panel, hierarchical) time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: broadcasting/vectorization of time series to time series transformer\n",
    "\n",
    "The `BoxCoxTransformer` from previous sections applies to single instances of univariate time series. When multiple instances or variables are seen, it broadcasts across both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.utils._testing.hierarchical import _make_hierarchical\n",
    "\n",
    "# hierarchical data with 2 variables and 2 levels\n",
    "X = _make_hierarchical(n_columns=2)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the transformers\n",
    "boxcox_trafo = BoxCoxTransformer(method=\"mle\")\n",
    "\n",
    "# applying to X results in hierarchical data\n",
    "boxcox_trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted model components of vectorized transformers can be found in the `transformers_` attribute, or accessed via the universal `get_fitted_params` interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_trafo.transformers_\n",
    "# this is a pandas.DataFrame that contains the fitted transformers\n",
    "# one per time series instance and variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_trafo.get_fitted_params()\n",
    "# this returns a dictionary\n",
    "# the transformers DataFrame is available at the key \"transformers\"\n",
    "# individual transformers are available at dataframe-like keys\n",
    "# it also contains all fitted lambdas as keyed parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: broadcasting/vectorization of time series to scalar features transformer\n",
    "\n",
    "The `SummaryTransformer` behaves similarly.\n",
    "Multiple time series instances are transformed to different columns of the resulting data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "summary_trafo = SummaryTransformer()\n",
    "\n",
    "# this produces a pandas DataFrame with more rows and columns\n",
    "# rows correspond to different instances in X\n",
    "# columns are multiplied and names prefixed by [variablename]__\n",
    "# there is one column per variable and transformed feature\n",
    "summary_trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sequential Pipelines, Combining Forecasters, and Feature Engineering\n",
    "\n",
    "`sktime` transformers can be pipelined with any other `sktime` estimator type, including forecasters, classifiers, and other transformers.\n",
    "\n",
    "Pipelines = estimators of the same type, same interface as specialized class\n",
    "\n",
    "pipeline build operation: `make_pipeline` or via `*` dunder\n",
    "\n",
    "Pipelining `pipe = trafo * est` produces `pipe` of same type as `est`.\n",
    "\n",
    "In `pipe.fit`, first `trafo.fit_transform`, then `est.fit` is executed on the result.\n",
    "\n",
    "In `pipe.predict`, first `trafo.transform`, then `est.predict` is executed.\n",
    "\n",
    "(the arguments that are piped differ by type and can be looked up in the docstrings of pipeline classes, or specialized tutorials)\n",
    "\n",
    "\n",
    "transformers are natural pipeline components\n",
    "\n",
    "* data processing steps\n",
    "* feature engineering steps\n",
    "* post processing steps\n",
    "\n",
    "they can be combined in a number of other ways:\n",
    "\n",
    "* pipelining = sequential chaining\n",
    "* feature union = parallel, addition of features\n",
    "* feature subsetting = selecting columns\n",
    "* inversion = switch transform and inverse\n",
    "* multiplexing = switching between transformers\n",
    "* passthrough = switch on/ off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Chaining transformers via `*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "pipe = Differencer() * SummaryTransformer()\n",
    "\n",
    "# this constructs a TransformerPipeline, which is also a transformer\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils._testing.hierarchical import _bottom_hier_datagen\n",
    "\n",
    "X = _bottom_hier_datagen(no_levels=1, no_bottom_nodes=2)\n",
    "\n",
    "# this is a transformer with the same interface\n",
    "# first applies differencer, then summary transform\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compatible with sklearn transformers!\n",
    "\n",
    "default applies sklearn transformer per individual time series as a data frame table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Differencer() * StandardScaler()\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline-adaptor chains can be constructed manually:\n",
    "\n",
    "* `sktime.transformations.compose.TransformerPipeline`\n",
    "* `sktime.transformations.series.adapt.TabularToSeriesAdaptor` for `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "composites are compatible with `get_params` / `set_params` parameter interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Feature union via `+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.lag import Lag\n",
    "\n",
    "pipe = Differencer() + Lag()\n",
    "\n",
    "# this constructs a FeatureUnion, which is also a transformer\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils._testing.hierarchical import _bottom_hier_datagen\n",
    "\n",
    "X = _bottom_hier_datagen(no_levels=1, no_bottom_nodes=2)\n",
    "\n",
    "# applies both Differencer and Lag, returns transformed in different columns\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to retain the original columns, use the `Id` transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import Id\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.lag import Lag\n",
    "\n",
    "pipe = Id() + Differencer() + Lag([1, 2], index_out=\"original\")\n",
    "\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter inspection\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Subset input columns via `[colname]`\n",
    "\n",
    "let's say we want to apply `Differencer` to column 0, and `Lag` to column 1\n",
    "\n",
    "also we keep the original columns for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils._testing.hierarchical import _make_hierarchical\n",
    "\n",
    "X = _make_hierarchical(\n",
    "    hierarchy_levels=(2, 2), n_columns=2, min_timepoints=3, max_timepoints=3\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import Id\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.lag import Lag\n",
    "\n",
    "pipe = Id() + Differencer()[\"c0\"] + Lag([1, 2], index_out=\"original\")[\"c1\"]\n",
    "\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto-generated names can be replaced by using `FeatureUnion` explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import FeatureUnion\n",
    "\n",
    "pipe = FeatureUnion(\n",
    "    [\n",
    "        (\"original\", Id()),\n",
    "        (\"diff\", Differencer()[\"c0\"]),\n",
    "        (\"lag\", Lag([1, 2], index_out=\"original\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see more later in part 3 on how to use this with tuning for full structural AutoML!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.4 Combining Transformers And Estimators (Example: forecaster pipeline)\n",
    "\n",
    "we have seen this example above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "\n",
    "y = load_airline()\n",
    "\n",
    "pipe = LogTransformer() * Deseasonalizer(sp=12) * PolynomialTrendForecaster(degree=2)\n",
    "\n",
    "pipe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.5 ColumnEnsemleTransformer and ColumnEnsembleForecaster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.6 Forecasting Exogenous Variables\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "y, X = load_longley()\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y=y, X=X, test_size=6)\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"]);\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import ForecastX\n",
    "from sktime.forecasting.var import VAR\n",
    "\n",
    "forecaster_X = ForecastX(\n",
    "    forecaster_y=AutoARIMA(sp=1, suppress_warnings=True),\n",
    "    forecaster_X=VAR(),\n",
    ")\n",
    "forecaster_X.fit(y=y, X=X, fh=fh)\n",
    "# now in predict() we don't need to pass X\n",
    "y_pred = forecaster_X.predict(fh=fh)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this is a forecaster with the same interface as Polynomial Trend Forecaster\n",
    "pipe.fit(y, fh=[1, 2, 3])\n",
    "y_pred = pipe.predict()\n",
    "\n",
    "plot_series(y, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Tuning\n",
    "* Lot of hyperparameters in a pipeline. We want to optimise them:\n",
    "\n",
    "### 1.4.1 Temporal Cross Validation\n",
    "\n",
    "In `sktime` there are three different types of temporal cross-validation splitters avilable:\n",
    "- `SingleWindowSplitter`, which is equivalent to a single train-test-split\n",
    "- `SlidingWindowSplitter`, which is using a rolling window approach and \"forgets\" the oldest observations as we move more into the future\n",
    "- `ExpandingWindowSplitter`, which is using a expanding window approach and keep all observations in the training set as we move more into the future\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "\n",
    "y = load_shampoo_sales()\n",
    "y_train, y_test = temporal_train_test_split(y=y, test_size=6)\n",
    "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"]);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ExpandingWindowSplitter,\n",
    "    SlidingWindowSplitter,\n",
    "    SingleWindowSplitter,\n",
    ")\n",
    "from sktime.utils.plotting import plot_windows\n",
    "\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False).to_relative(\n",
    "    cutoff=y_train.index[-1]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv = SingleWindowSplitter(fh=fh, window_length=len(y_train) - 6)\n",
    "plot_windows(cv=cv, y=y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv = SlidingWindowSplitter(fh=fh, window_length=12, step_length=1)\n",
    "plot_windows(cv=cv, y=y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv = ExpandingWindowSplitter(fh=fh, initial_window=12, step_length=1)\n",
    "plot_windows(cv=cv, y=y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get number of total splits (folds)\n",
    "cv.get_n_splits(y=y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.2 Grid Search\n",
    "\n",
    "For tuning parameters with compositions such as pipelines, we can use the \\<estimator\\>__\\<parameter\\> syntax known from [scikit-learn](https://scikit-learn.org/stable/modules/grid_search.html#composite-estimators-and-parameter-spaces). For multiple levels of nesting, we can use the same syntax with two underscores, e.g. `forecaster__transformer__parameter`.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, MinMaxScaler\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "\n",
    "forecaster = TransformedTargetForecaster(\n",
    "    steps=[\n",
    "        (\"detrender\", Detrender()),\n",
    "        (\"deseasonalizer\", Deseasonalizer()),\n",
    "        (\"minmax\", TabularToSeriesAdaptor(MinMaxScaler((1, 10)))),\n",
    "        (\"power\", TabularToSeriesAdaptor(PowerTransformer())),\n",
    "        (\"scaler\", TabularToSeriesAdaptor(RobustScaler())),\n",
    "        (\"forecaster\", ExponentialSmoothing()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# using dunder notation to access inner objects/params as in sklearn\n",
    "param_grid = {\n",
    "    # deseasonalizer\n",
    "    \"deseasonalizer__model\": [\"multiplicative\", \"additive\"],\n",
    "    # power\n",
    "    \"power__transformer__method\": [\"yeo-johnson\", \"box-cox\"],\n",
    "    \"power__transformer__standardize\": [True, False],\n",
    "    # forecaster\n",
    "    \"forecaster__sp\": [4, 6, 12],\n",
    "    \"forecaster__seasonal\": [\"add\", \"mul\"],\n",
    "    \"forecaster__trend\": [\"add\", \"mul\"],\n",
    "    \"forecaster__damped_trend\": [True, False],\n",
    "}\n",
    "\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster=forecaster,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring=MeanSquaredError(square_root=True),  # set custom scoring function\n",
    ")\n",
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh=fh)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]);\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gscv.best_params_\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gscv.best_forecaster_\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gscv.cv_results_.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5 Summary<a class=\"anchor\" id=\"chapter5\"></a>\n",
    "\n",
    "* transformers are data processing steps with unified interface - `fit`, `transform`, and optional `inverse_transform`\n",
    "\n",
    "* used as pipeline components for any learning task, forecasting, classification\n",
    "\n",
    "* different types by input/output - time series, primitives, pairs of time series, panels/hierarchical.\n",
    "\n",
    "* find transformers by tags such as `scitype:transform-output` and `scitype:instancewise` using `all_estimators`\n",
    "\n",
    "* rich composition syntax - `*` for pipe, `+` for featureunion, `[in, out]` for variable subset, `|` for multiplex/switch\n",
    "\n",
    "* `sktime` provides easy-to-use extension templates for transformers, build your own, plug and play"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Appendix - cheat sheets and extension guie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dunders glossary\n",
    "\n",
    "| Type | Dunder | Meaning | `sktime` class |\n",
    "| --- | --- | --- | --- |\n",
    "| compose | `*` | chaining/pipeline - also works with other estimator types | type dependent |\n",
    "| compose | `**` | chaining to secondary input of another estimator | type dependent |\n",
    "| compose | `+` | feature union | `FeatureUnion` |\n",
    "| interface | `~` | invert | `InvertTransform` |\n",
    "| structural | `Â¦` | multiplexing (\"switch\") | type dependent |\n",
    "| structural | `-` | optional passthrough (\"on/off\") | `OptionalPassthrough` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selected useful transformers, compositors, adapters\n",
    "\n",
    "* delay fitting to `transform` via `sktime.transformations.compose.FitInTransform`\n",
    "* any `pandas` method via `sktime.transformations.compose.adapt.PandasTransformAdaptor`\n",
    "* date/time features via `sktime.transformations.series.date.DateTimeFeatures`\n",
    "* lags via `transformations.series.lag.Lag`\n",
    "* differences, first and n-th, via `transformations.series.difference.Differencer`\n",
    "* scaled logit via `transformations.series.scaledlogit.ScaledLogitTransform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension guide - implementing your own transformer<a class=\"anchor\" id=\"chapter4\"></a>\n",
    "\n",
    "`sktime` is meant to be easily extensible, for direct contribution to `sktime` as well as for local/private extension with custom methods.\n",
    "\n",
    "To extend `sktime` with a new local or contributed transformer, a good workflow to follow is:\n",
    "\n",
    "1. read through the [transformer extension template](https://github.com/alan-turing-institute/sktime/blob/main/extension_templates/transformer.py) - this is a `python` file with `todo` blocks that mark the places in which changes need to be added.\n",
    "2. optionally, if you are planning any major surgeries to the interface: look at the [base class architecture](https://github.com/alan-turing-institute/sktime/blob/main/sktime/transformations/base.py) - note that \"ordinary\" extension (e.g., new algorithm) should be easily doable without this.\n",
    "3. copy the transformer extension template to a local folder in your own repository (local/private extension), or to a suitable location in your clone of the `sktime` or affiliated repository (if contributed extension), inside `sktime.transformations`; rename the file and update the file docstring appropriately.\n",
    "4. address the \"todo\" parts. Usually, this means: changing the name of the class, setting the tag values, specifying hyper-parameters, filling in `__init__`, `_fit`, `_transform`, and optional methods such as `_inverse_transform` or `_update` (for details see the extension template). You can add private methods as long as they do not override the default public interface. For more details, see the extension template.\n",
    "5. to test your estimator manually: import your estimator and run it in the worfklows in Section 2.2; then use it in the compositors in Section 2.3.\n",
    "6. to test your estimator automatically: call `sktime.tests.test_all_estimators.check_estimator` on your estimator. You can call this on a class or object instance. Ensure you have specified test parameters in the `get_test_params` method, according to the extension template.\n",
    "\n",
    "In case of direct contribution to `sktime` or one of its affiliated packages, additionally:\n",
    "* add yourself as an author to the code, and to the `CODEOWNERS` for the new estimator file(s).\n",
    "* create a pull request that contains only the new estimators (and their inheritance tree, if it's not just one class), as well as the automated tests as described above.\n",
    "* in the pull request, describe the estimator and optimally provide a publication or other technical reference for the strategy it implements.\n",
    "* before making the pull request, ensure that you have all necessary permissions to contribute the code to a permissive license (BSD-3) open source project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Credits: notebook 2 - transformers\n",
    "\n",
    "notebook creation: fkiraly\n",
    "\n",
    "transformer pipelines & compositors: fkiraly, mloning, miraep8\\\n",
    "forecaster pipelines: fkiraly, aiwalter\\\n",
    "classifier/regressor pipelines: fkiraly\\\n",
    "transformer base interface: mloning, fkiraly\\\n",
    "dunder interface: fkiraly, miraep8\n",
    "\n",
    "Based on design ideas: sklearn, magrittr, mlr, mlj"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pydata22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e61b44dca3bf47c8973c8cd627825697e2dad493e19dd6592afda0a0a3c312a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
